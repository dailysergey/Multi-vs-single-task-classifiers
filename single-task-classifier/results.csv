model,task,seed,train_accuracy,test_accuracy,train_f1,test_f1
roberta-base,mrpc,42,0.935659760087241,0.8799019607843137,0.9527622097678142,0.9144851657940662
roberta-base,mrpc,43,0.91793893129771,0.8774509803921569,0.9388584196628074,0.910394265232975
roberta-base,mrpc,44,0.9539258451472192,0.8921568627450981,0.9657686854365,0.9219858156028368
roberta-base,cola,44,0.9514676646006316,0.835091083413231,0.9657675492864802,0.8853333333333333
roberta-base,cola,43,0.8884341012747047,0.8207094918504314,0.9223127035830616,0.8770545693622617
roberta-base,cola,42,0.8893696643667407,0.8130393096836049,0.9244891443167303,0.8744365743721829
roberta-base,sst2,42,0.9637114136809752,0.9311926605504588,0.9671999141077948,0.931350114416476
roberta-base,sst2,43,0.978143699238296,0.930045871559633,0.9805022782663982,0.9324473975636768
roberta-base,sst2,44,0.9797472865224428,0.9369266055045872,0.981778834593497,0.9378531073446327
